# ğŸ¶ Instrument Activation Detection with CRNN

## ğŸ§  Project Overview

This project focuses on **frame-level detection of musical instrument activations** in audio tracks. The task is **multi-label classification**, where multiple instruments may be active simultaneously at each time frame. The goal is to predict which instruments are active at any point in time during a song.

We use the **AAM Dataset**, a publicly available collection of `.wav` tracks and corresponding `.arff` files that contain segment-level annotations with ground truth instruments.

---

## ğŸ“ Dataset

- **Dataset Used**: [Artificial Audio Multitracks (AAM)](https://zenodo.org/record/8040391)
- **Contents**:
  - `.wav` audio files for analysis and feature extraction.
  - `.arff` annotation files with segment-level instrument activity.
- **Preprocessing**:
  - Extraction of **Mel Spectrograms**.
  - Creation of frame-level multi-hot label matrices.
- **Ground Truth**:
  - Instrument labels per time frame obtained from the annotations.

We originally attempted to work with **MedleyDB**, but access limitations led us to opt for AAM instead.

---

## ğŸ—ï¸ Model Architectures

We experimented with two core architectures:

### ğŸ”¹ Baseline: MLP (Multi-Layer Perceptron)
- Simple feed-forward model.
- Performs decently even with small datasets.
- Useful for benchmarking.

### ğŸ”¹ Proposed: CRNN (Convolutional Recurrent Neural Network)
- Combines CNNs for spectral pattern recognition and LSTMs for temporal modeling.
- Performs worse than MLP on low-data regimes.
- Outperforms MLP as the amount of training data increases.

---

## âš–ï¸ Class Imbalance Handling

- Observed rare classes (instruments that appear in very few tracks).
- Solutions applied:
  - **Oversampling** tracks with rare instrument classes.
  - **Weighted loss averaging**.

---

## ğŸ“Š Evaluation

We evaluated model performance both quantitatively and qualitatively.

### ğŸ§® Metrics
- **F1-Score** (Macro, Micro, Weighted)
- **Hamming Loss**
- **Jaccard Index**

### ğŸ¨ Visual Inspection
- Per-track **frame-level visualization** of predictions vs. ground truth.
- Highlighting correct (green) and incorrect (red) predictions.
- Useful for spotting systematic errors per instrument.

---

## âŒ Confusion Analysis

- Identification of **instrument confusions**, especially for sonically overlapping instruments.
- Built confusion heatmaps to analyze model errors (e.g., Flute vs. Violin).

---

## ğŸš€ Future Work (as of June 12, 2025)

- **Expand training data** using the full AAM dataset or additional corpora.
- **Experiment with hyperparameter tuning** (e.g., learning rate, batch size, network depth).
- Explore **data augmentation** techniques.
- Try **attention-based** or **transformer-based** architectures for improved temporal modeling.

---

## ğŸ”§ Requirements

- Python â‰¥ 3.9
- PyTorch
- Librosa
- Plotly
- Scikit-learn
- Pandas

---


## v3 30 Jun 2025

- ÎšÏÎ´Î¹ÎºÎµÏ‚:
  - Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Ï‚ Î³Î¹Î± ÎµÏ€Î¹Î»Î¿Î³Î®: Ï€ÏŒÏƒÎ± Ï„ÏÎ±Î³Î¿ÏÎ´Î¹Î± Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹ ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿ & Ï€ÏŒÏƒÎ± epochs.
  - Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎµ early stopping Î¼Îµ patience, ÏÏƒÏ„Îµ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· Î® Î±ÏÏ‡Î¯Î¶ÎµÎ¹ overfitting, Î½Î± Ï„ÎµÏÎ¼Î±Ï„Î¯Î¶ÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.
  - Î¥Î»Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ Î±Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… checkpoint (best model) ÎºÎ±Ï„Î¬ Ï„Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î± Ï„Î·Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ â€” Ï„ÏÏÎ± ÎºÏÎ±Ï„Î¬Î¼Îµ ÏŒÎ»Î± Ï„Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ trained Î¼Î¿Î½Ï„Î­Î»Î± ÏƒÏ„Î¿ Ï†Î¬ÎºÎµÎ»Î¿ saved_models/.
- ÎÎ­Î¿ notebook:
  - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ notebook ([text](notebooks/04_Real_Case.ipynb)) Ï€Î¿Ï… Î´Î­Ï‡ÎµÏ„Î±Î¹ Î­Î½Î± custom Ï„ÏÎ±Î³Î¿ÏÎ´Î¹ (Ï€.Ï‡. new_song.wav), Ï„ÏÎ­Ï‡ÎµÎ¹ ÏŒÎ»Î± Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ Ï†Ï„Î¹Î¬Ï‡Î½ÎµÎ¹ ÏƒÏ…Î³ÎºÏÎ¹Ï„Î¹ÎºÏŒ report Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ ÏÏƒÏ„Îµ Î½Î± ÎµÎ»Î­Î³Ï‡Î¿Ï…Î¼Îµ Ï€ÏÏ‚ ÏƒÏ…Î¼Ï†Ï‰Î½Î¿ÏÎ½ Î¼Îµ Ï„Î·Î½ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ® Î¼Î±Ï‚ Î±Î½Ï„Î¯Î»Î·ÏˆÎ·.

  